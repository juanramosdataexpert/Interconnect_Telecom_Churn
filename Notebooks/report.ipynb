{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0F19C9\">Contenido</span>\n",
    "\n",
    "- [Plan](#plan)\n",
    "- [Pasos Claves](#pasos-claves)\n",
    "- [Modelo Final](#modelo-final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0F19C9\">Plan</span>\n",
    "\n",
    "Se definieron 8 pasos de ejecución específica para el proyecto, de los cuales se desarrollaron efectivamente 6, en el siguiente orden:\n",
    "- **Análisis Inicial:** Se verificó la integridad de los datos, su calidad, el formato en que venían, valores atípicos, entre otras cosas para terminar en un análisis estadístico más a profundidad en donde se pudieron establecer las relaciones más importantes para el negocio. En esta última parte se desarrollaron pruebas estadísticas T de Student para verificar las diferencias significativas entre dos variables numéricas y pruebas V de Cramér para demostrar relaciones, y su respectiva fuerza, entre dos variables categóricas.\n",
    "- **Construcción del Dataframe Principal:** Juntamos toda la información, basándonos en el identificador de cada cliente, en un solo dataframe que contendría toda la información para el entrenamiento y evaluación de los Modelos de Machine Learning. Luego, estos datos se divieron en 3 partes:\n",
    "    - El 60% de ellos se usó para entrenamiento.\n",
    "    - El 20% de ellos se usó para validación.\n",
    "    - El 20% de ellos se usó para prueba.\n",
    "- **Análisis de Componentes Principales:** Una vez se entrenaron unos modelos básicos y logramos identificar el que mejor desempeño tuvo, también logramos demostrar que reducir la dimensionalidad de nuestro dataframe final de 20 características a 12 nos daba la mejor métrica ROC-AUC que fue la que el negocio nos pidió evaluar. Aquí encontramos el paso que no se desarrolló que era poder confrontar la información proporcionada por el Análisis Inicial con el Análisis de Componentes Principales, no se cómo se hace esto técnicamente.\n",
    "- **Entrenamiento del modelo:** Una vez se entendió que nos enfrentábamos a un problema de clasificación, determinar si un cliente continuaría con nosotros y lo evaluara con un 1; o nos abandonaría y lo evaluara con un 0, entrenamos modelos de Aprendizaje Supervisado de Clasificación de las librerías SciKit-Learn, CatBoost (por la gran cantidad de variables categóricas que teníamos) y LightGBM por su velocidad para el entrenamiento y la predicción. Al final, quien mejor métrica ROC-AUC nos arrojó fue la Red Neuronal de SciKit-Learn.\n",
    "- **Afinación de hiperparámetros:** El siguiente paso consistió en afinar los hiperparámetros tanto del modelo, pero antes de eso, volver a revisar la mejor cantidad de características del Análisis de Componentes Principales. Esto se hizo con un iterador sobre los PCA y una búsqueda en rejilla de SciKit-Learn. Esto nos llevó a modificar la función de activación relu, por una logística; también disminuimos el número de neuronas en las capas ocultas de 200 a 100 y así, reducir considerablemente por estos cambios, tanto el tiempo de entrenamiento como el tiempo de predicción.\n",
    "- **Aplicación sobre los datos de prueba:** Como último paso del plan, decidimos aplicar nuestro modelo afinado con el último conjunto de datos que el modelo nunca había visto, lo que sería lo más cercano a un escenario real logrando una métrica ROC-AUC de 70.09%. Finalmente redactamos el presente informe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0F19C9\">Pasos Claves</span>\n",
    "\n",
    "Siento que los pasos más importantes estuvieron en el Análisis Exploratorio de Datos pero que, a causa de falta de conocimiento de la aplicación técnica, no fueron utilizados en el entrenamiento de nuestro modelo, que hubiera sido importante haber podido controlarlos de alguna forma. \n",
    "\n",
    "El primer paso clave fue la creación de ese dataframe único que tuviera todas las características de un cliente específico y luego poder codificarlas, tanto las categóricas, como escalar las numéricas, esto eliminó los sesgos que pudiera generar algún modelo de entrenamiento, principalmente los que se entrenan a partir de distancias, o como en nuestro caso final, en nuestra Red Neuronal pues iniciaba sus iteraciones con pesos realmente aleatorios.\n",
    "\n",
    "Y el segundo paso clave en todo nuestra creación de modelo fueron los pasos de PCA con la misma cantidad de características, luego elección del modelo, luego afinación de PCA y finalmente afinación del modelo. Estos pasos nos iban dando conclusiones importantes sobre nuestro conjunto de datos que poco a poco fueron construyendo a mejorar nuestra métrica ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0F19C9\">Modelo Final</span>\n",
    "\n",
    "El modelo de Machine Learning de Aprendizaje Supervisado de Clasificación que mejor métrica ROC-AUC tuvo fue la Red Neuronal de la librería SciKit-Learn conocida como `MLPClassifier`. Esta red cuenta con: \n",
    "- Una capa oculta de 100 neuronas\n",
    "- Función de activación logística\n",
    "- Algoritmo de optimización de pesos adam\n",
    "- Término de regularización L2 de 0.0001\n",
    "- Tasa de aprendizaje constante e inicial de 0.001\n",
    "- Máximo de número de iteraciones de 200, que para nuestro optimizador adam esto significa el número de epochs, es decir, el número de veces que cada punto es usado.\n",
    "\n",
    "Además, para entrenarse pasó por una reducción de dimensionalidad PCA de 20 componentes a 12. De esta forma logramos:\n",
    "- ROC-AUC de nuestro modelo de 0.7009946495784988\n",
    "- Tiempo de entrenamiento para 1000 registros de 0:00:00.443279 milisegundos\n",
    "- Tiempo de predicción para 1000 registros es de 0:00:00.004640 milisegundos"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
